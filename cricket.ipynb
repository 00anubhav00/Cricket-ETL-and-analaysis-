{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e00acbd1-9454-4f41-a506-bd4085eeabe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed all_json\n",
      "‚úÖ Processed ipl_json\n",
      "‚úÖ Processed mdms_json\n",
      "‚úÖ Processed odis_json\n",
      "‚úÖ Processed t20s_json\n",
      "‚úÖ Processed tests_json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def process_json(json_file, matches_rows, info_rows, ball_rows):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    info = data.get(\"info\", {})\n",
    "    match_id = os.path.splitext(os.path.basename(json_file))[0]\n",
    "\n",
    "    # ---------- Matches.csv ----------\n",
    "    matches_rows.append({\n",
    "        \"match_id\": match_id,\n",
    "        \"team_type\": info.get(\"team_type\"),\n",
    "        \"match_type\": info.get(\"match_type\"),\n",
    "        \"city\": info.get(\"city\"),\n",
    "        \"venue\": info.get(\"venue\"),\n",
    "        \"winner\": info.get(\"outcome\", {}).get(\"winner\"),\n",
    "        \"season\": info.get(\"season\"),\n",
    "        \"teams\": \",\".join(info.get(\"teams\", [])),\n",
    "        \"dates\": \",\".join(info.get(\"dates\", [])),\n",
    "    })\n",
    "\n",
    "    # ---------- Info_summary.csv ----------\n",
    "    info_rows.append({\n",
    "        \"match_id\": match_id,\n",
    "        \"balls_per_over\": info.get(\"balls_per_over\"),\n",
    "        \"gender\": info.get(\"gender\"),\n",
    "        \"event_name\": info.get(\"event\", {}).get(\"name\"),\n",
    "        \"match_number\": info.get(\"event\", {}).get(\"match_number\"),\n",
    "        \"match_type_number\": info.get(\"match_type_number\"),\n",
    "        \"toss_winner\": info.get(\"toss\", {}).get(\"winner\"),\n",
    "        \"toss_decision\": info.get(\"toss\", {}).get(\"decision\"),\n",
    "    })\n",
    "\n",
    "    # ---------- Ballbyball.csv ----------\n",
    "    for inning_idx, inning in enumerate(data.get(\"innings\", []), start=1):\n",
    "        team = inning.get(\"team\")\n",
    "        for over in inning.get(\"overs\", []):\n",
    "            over_num = over.get(\"over\")\n",
    "            for ball_idx, delivery in enumerate(over.get(\"deliveries\", []), start=1):\n",
    "                # Extract wicket details\n",
    "                wicket_type = \"\"\n",
    "                wicket_player_out = \"\"\n",
    "                fielders = []\n",
    "                if \"wickets\" in delivery:\n",
    "                    for w in delivery[\"wickets\"]:\n",
    "                        if \"kind\" in w:\n",
    "                            wicket_type = w.get(\"kind\", \"\")\n",
    "                        if \"player_out\" in w:\n",
    "                            wicket_player_out = w.get(\"player_out\", \"\")\n",
    "                        if \"fielders\" in w:\n",
    "                            fielders.extend([f.get(\"name\", \"\") for f in w.get(\"fielders\", [])])\n",
    "\n",
    "                # Extract extras type (wide, no-ball, bye, etc.)\n",
    "                extras_type = \"\"\n",
    "                if \"extras\" in delivery:\n",
    "                    extras_type = \";\".join(delivery[\"extras\"].keys())\n",
    "\n",
    "                row = {\n",
    "                    \"match_id\": match_id,\n",
    "                    \"inning\": inning_idx,\n",
    "                    \"team\": team,\n",
    "                    \"date\": info.get(\"dates\", [None])[0],\n",
    "                    \"over\": over_num,\n",
    "                    \"ball\": ball_idx,\n",
    "                    \"batter\": delivery.get(\"batter\"),\n",
    "                    \"bowler\": delivery.get(\"bowler\"),\n",
    "                    \"non_striker\": delivery.get(\"non_striker\"),\n",
    "                    \"runs_batter\": delivery.get(\"runs\", {}).get(\"batter\", 0),\n",
    "                    \"runs_extras\": delivery.get(\"runs\", {}).get(\"extras\", 0),\n",
    "                    \"runs_total\": delivery.get(\"runs\", {}).get(\"total\", 0),\n",
    "                    \"extras_type\": extras_type,\n",
    "                    \"wicket_type\": wicket_type,\n",
    "                    \"wicket_player_out\": wicket_player_out,\n",
    "                    \"fielders\": \";\".join([f for f in fielders if f])\n",
    "                }\n",
    "                ball_rows.append(row)\n",
    "\n",
    "def save_csv(rows, filepath, fieldnames):\n",
    "    if not rows:\n",
    "        return\n",
    "    with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "def process_folder(folder):\n",
    "    matches_rows, info_rows, ball_rows = [], [], []\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".json\"):\n",
    "            process_json(os.path.join(folder, file), matches_rows, info_rows, ball_rows)\n",
    "\n",
    "    analysis_path = os.path.join(\"cricket/analysis\", os.path.basename(folder))\n",
    "    os.makedirs(analysis_path, exist_ok=True)\n",
    "\n",
    "    save_csv(matches_rows, os.path.join(analysis_path, \"matches.csv\"),\n",
    "             [\"match_id\",\"team_type\",\"match_type\",\"city\",\"venue\",\"winner\",\"season\",\"teams\",\"dates\"])\n",
    "\n",
    "    save_csv(info_rows, os.path.join(analysis_path, \"info_summary.csv\"),\n",
    "             [\"match_id\",\"balls_per_over\",\"gender\",\"event_name\",\"match_number\",\"match_type_number\",\"toss_winner\",\"toss_decision\"])\n",
    "\n",
    "    save_csv(ball_rows, os.path.join(analysis_path, \"ballbyball.csv\"),\n",
    "             [\"match_id\",\"inning\",\"team\",\"date\",\"over\",\"ball\",\"batter\",\"bowler\",\"non_striker\",\n",
    "              \"runs_batter\",\"runs_extras\",\"runs_total\",\"extras_type\",\"wicket_type\",\"wicket_player_out\",\"fielders\"])\n",
    "\n",
    "# ---------- Run for all 6 folders ----------\n",
    "subfolders = [\"all_json\",\"ipl_json\",\"mdms_json\",\"odis_json\",\"t20s_json\",\"tests_json\"]\n",
    "for sub in subfolders:\n",
    "    process_folder(os.path.join(\"cricket\", sub))\n",
    "    print(f\"‚úÖ Processed {sub}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33998941-55c3-4add-a5db-6c413103406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Processing players for all_json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/7v8ms1r93s335hb5qdf2d4lw0000gn/T/ipykernel_20561/994590549.py:57: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  fielder_df = df[df[\"fielders\"].fillna(\"\").str.contains(player)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed all_json, created 8238 player folders\n",
      "üîÑ Processing players for ipl_json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/7v8ms1r93s335hb5qdf2d4lw0000gn/T/ipykernel_20561/994590549.py:57: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  fielder_df = df[df[\"fielders\"].fillna(\"\").str.contains(player)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed ipl_json, created 778 player folders\n",
      "üîÑ Processing players for mdms_json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/7v8ms1r93s335hb5qdf2d4lw0000gn/T/ipykernel_20561/994590549.py:57: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  fielder_df = df[df[\"fielders\"].fillna(\"\").str.contains(player)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed mdms_json, created 1997 player folders\n",
      "üîÑ Processing players for odis_json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/7v8ms1r93s335hb5qdf2d4lw0000gn/T/ipykernel_20561/994590549.py:57: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  fielder_df = df[df[\"fielders\"].fillna(\"\").str.contains(player)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed odis_json, created 2568 player folders\n",
      "üîÑ Processing players for t20s_json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/7v8ms1r93s335hb5qdf2d4lw0000gn/T/ipykernel_20561/994590549.py:57: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  fielder_df = df[df[\"fielders\"].fillna(\"\").str.contains(player)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed t20s_json, created 6501 player folders\n",
      "üîÑ Processing players for tests_json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/7v8ms1r93s335hb5qdf2d4lw0000gn/T/ipykernel_20561/994590549.py:57: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  fielder_df = df[df[\"fielders\"].fillna(\"\").str.contains(player)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed tests_json, created 1210 player folders\n",
      "üéâ Player CSVs created for all folders\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "base_folder = \"cricket/analysis\"\n",
    "subfolders = [\"all_json\",\"ipl_json\",\"mdms_json\",\"odis_json\",\"t20s_json\",\"tests_json\"]\n",
    "\n",
    "def process_players(sub):\n",
    "    print(f\"üîÑ Processing players for {sub} ...\")\n",
    "\n",
    "    analysis_path = os.path.join(base_folder, sub)\n",
    "    ballbyball_path = os.path.join(analysis_path, \"ballbyball.csv\")\n",
    "    if not os.path.exists(ballbyball_path):\n",
    "        print(f\"‚ö†Ô∏è Skipping {sub}, no ballbyball.csv\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(ballbyball_path)\n",
    "\n",
    "    # Collect all unique players from batter, non_striker, bowler, fielders\n",
    "    players = set(df[\"batter\"].dropna()) \\\n",
    "              | set(df[\"non_striker\"].dropna()) \\\n",
    "              | set(df[\"bowler\"].dropna())\n",
    "\n",
    "    # Fielders column is semicolon-separated\n",
    "    if \"fielders\" in df.columns:\n",
    "        for f_list in df[\"fielders\"].dropna():\n",
    "            for f in str(f_list).split(\";\"):\n",
    "                if f.strip():\n",
    "                    players.add(f.strip())\n",
    "\n",
    "    # Create player folders\n",
    "    player_base = os.path.join(analysis_path, \"player\")\n",
    "    os.makedirs(player_base, exist_ok=True)\n",
    "\n",
    "    for player in players:\n",
    "        safe_name = player.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\" \", \"_\")\n",
    "        player_folder = os.path.join(player_base, safe_name)\n",
    "        os.makedirs(player_folder, exist_ok=True)\n",
    "\n",
    "        # 1. Batter\n",
    "        batter_df = df[df[\"batter\"] == player]\n",
    "        if not batter_df.empty:\n",
    "            batter_df.to_csv(os.path.join(player_folder, \"batter.csv\"), index=False)\n",
    "\n",
    "        # 2. Non-striker\n",
    "        non_striker_df = df[df[\"non_striker\"] == player]\n",
    "        if not non_striker_df.empty:\n",
    "            non_striker_df.to_csv(os.path.join(player_folder, \"non_striker.csv\"), index=False)\n",
    "\n",
    "        # 3. Bowler\n",
    "        bowler_df = df[df[\"bowler\"] == player]\n",
    "        if not bowler_df.empty:\n",
    "            bowler_df.to_csv(os.path.join(player_folder, \"bowler.csv\"), index=False)\n",
    "\n",
    "        # 4. Fielder\n",
    "        if \"fielders\" in df.columns:\n",
    "            fielder_df = df[df[\"fielders\"].fillna(\"\").str.contains(player)]\n",
    "            if not fielder_df.empty:\n",
    "                fielder_df.to_csv(os.path.join(player_folder, \"fielder.csv\"), index=False)\n",
    "\n",
    "        # 5. Batter or Non-striker\n",
    "        bat_or_non_df = df[(df[\"batter\"] == player) | (df[\"non_striker\"] == player)]\n",
    "        if not bat_or_non_df.empty:\n",
    "            bat_or_non_df.to_csv(os.path.join(player_folder, \"batter_or_non_striker.csv\"), index=False)\n",
    "\n",
    "    print(f\"‚úÖ Completed {sub}, created {len(players)} player folders\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for sub in subfolders:\n",
    "        process_players(sub)\n",
    "    print(\"üéâ Player CSVs created for all folders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea3eafa-e482-40bd-84d9-b7ca0d19e594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Processing teams for all_json ...\n",
      "‚úÖ Completed all_json, 109 teams processed\n",
      "üîÑ Processing teams for ipl_json ...\n",
      "‚úÖ Completed ipl_json, 19 teams processed\n",
      "üîÑ Processing teams for mdms_json ...\n",
      "‚úÖ Completed mdms_json, 58 teams processed\n",
      "üîÑ Processing teams for odis_json ...\n",
      "‚úÖ Completed odis_json, 28 teams processed\n",
      "üîÑ Processing teams for t20s_json ...\n",
      "‚úÖ Completed t20s_json, 106 teams processed\n",
      "üîÑ Processing teams for tests_json ...\n",
      "‚úÖ Completed tests_json, 12 teams processed\n",
      "üéâ Team CSVs created for all folders\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_folder = \"cricket/analysis\"\n",
    "subfolders = [\"all_json\",\"ipl_json\",\"mdms_json\",\"odis_json\",\"t20s_json\",\"tests_json\"]\n",
    "\n",
    "def process_teams(sub):\n",
    "    print(f\"üîÑ Processing teams for {sub} ...\")\n",
    "\n",
    "    folder = os.path.join(base_folder, sub)\n",
    "    team_folder = os.path.join(folder, \"team\")\n",
    "    os.makedirs(team_folder, exist_ok=True)\n",
    "\n",
    "    # Load ballbyball and matches\n",
    "    ball_path = os.path.join(folder, \"ballbyball.csv\")\n",
    "    match_path = os.path.join(folder, \"matches.csv\")\n",
    "    if not os.path.exists(ball_path) or not os.path.exists(match_path):\n",
    "        print(f\"‚ö†Ô∏è Missing ballbyball or matches in {sub}, skipping.\")\n",
    "        return\n",
    "\n",
    "    ball_df = pd.read_csv(ball_path)\n",
    "    matches_df = pd.read_csv(match_path)\n",
    "\n",
    "    # Build match_id ‚Üí [team1, team2] mapping\n",
    "    match_teams = {}\n",
    "    for _, row in matches_df.iterrows():\n",
    "        if \"match_id\" in row and \"teams\" in row:\n",
    "            tlist = str(row[\"teams\"]).split(\",\")\n",
    "            match_teams[row[\"match_id\"]] = [t.strip() for t in tlist]\n",
    "\n",
    "    # Collect all unique teams\n",
    "    unique_teams = set()\n",
    "    if \"team\" in ball_df.columns:\n",
    "        unique_teams.update(ball_df[\"team\"].dropna().unique())\n",
    "    for tlist in matches_df[\"teams\"].dropna():\n",
    "        for t in str(tlist).split(\",\"):\n",
    "            unique_teams.add(t.strip())\n",
    "\n",
    "    # Process each team\n",
    "    for team in unique_teams:\n",
    "        team_dir = os.path.join(team_folder, team.replace(\" \", \"_\"))\n",
    "        os.makedirs(team_dir, exist_ok=True)\n",
    "\n",
    "        # Batting\n",
    "        batting_df = ball_df[ball_df[\"team\"] == team]\n",
    "        if not batting_df.empty:\n",
    "            batting_df.to_csv(os.path.join(team_dir, \"batting.csv\"), index=False)\n",
    "\n",
    "        # Bowling + Fielding\n",
    "        bowling_rows = []\n",
    "        fielding_rows = []\n",
    "\n",
    "        for _, row in ball_df.iterrows():\n",
    "            mid = row[\"match_id\"]\n",
    "            batting_team = row[\"team\"]\n",
    "            if mid not in match_teams:\n",
    "                continue\n",
    "            teams = match_teams[mid]\n",
    "            if len(teams) < 2:\n",
    "                continue\n",
    "            bowling_team = teams[0] if teams[1] == batting_team else teams[1]\n",
    "\n",
    "            if bowling_team == team:\n",
    "                bowling_rows.append(row)\n",
    "                if pd.notna(row.get(\"wicket_type\")) and row[\"wicket_type\"] != \"\":\n",
    "                    fielding_rows.append(row)\n",
    "\n",
    "        if bowling_rows:\n",
    "            pd.DataFrame(bowling_rows).to_csv(os.path.join(team_dir, \"bowling.csv\"), index=False)\n",
    "        if fielding_rows:\n",
    "            pd.DataFrame(fielding_rows).to_csv(os.path.join(team_dir, \"fielding.csv\"), index=False)\n",
    "\n",
    "    print(f\"‚úÖ Completed {sub}, {len(unique_teams)} teams processed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for sub in subfolders:\n",
    "        process_teams(sub)\n",
    "    print(\"üéâ Team CSVs created for all folders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab40f5f-bef4-406c-9c2a-fd224e7c77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "while ipl is selected show following\n",
    "-a pie chart of count of 0 1 2 3 4 6 from runs_batter column in ballbyball.csv in ipl_json folder in analysis folder followed by table for the same\n",
    "-a pie chart of count of every wicket type from wicket_type column in ballbyball.csv in ipl_json folder in analysis folder followed by table for the same\n",
    "- a pie chart count of extras type from extras_type column in ballbyball.csv in ipl_json folder in analysis folder followed by table for the same                                                                                                                                                  \n",
    "-table for total runs sum of runs_total column , total wicket sum of count of wicket_type column,total extras sum of runs_extras column , total balls bowled total number of rows in ballbyball.csv in ipl_json folder in analysis folder\n",
    "-bargraph for top 10 most run getter you can calc this from runs_batter column in batter.csv in player names in player folder in ipl_json folder in analysis folder\n",
    "-bargraph of top 10 wicket taker you can cal this from wicket_type column in bowler.csv in player names in player folder in ipl_json folder in analysis folder\n",
    "-bargrapg of top 10 most catch/runout taken then also make table for them for total number of catches total number of runouts you can cal this from fielder column in fielder.csv in player names in player folder in ipl_json folder in analysis folder\n",
    "-bargraph and table fro count of toss won by which team from toss_winner column info_summary.csv in ipl_json folder\n",
    "--bargraph and table fro count of toss won setted batting or bowling by which team from toss_winner and toss_decision column info_summary.csv in ipl_json folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4176c3-678b-45b6-b34d-d3ee7b12514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "now i wnat to create a dashboard for analysis folder \n",
    "which contains following drop downs\n",
    "- 'matches' which contails folder inside analysis folder ,all_json as all internatinal matches ,ipl_json as ipl matches,mdms_json as multiday matches, odis_json as odi matches ,t20s_json as t20 international matches, tests_json as test matches\n",
    "- 'team' containg all the unique teams from the seleted folder in matches dropdown\n",
    "- 'player' containg all the players played for selected team from the team dropdown\n",
    "\n",
    "while ipl is selected show following\n",
    "-a pie chart of count of 0 1 2 3 4 6 from runs_batter column in ballbyball.csv in all_json folder in analysis folder followed by table for the same\n",
    "-a pie chart of count of every wicket type from wicket_type column in ballbyball.csv in all_json folder in analysis folder followed by table for the same\n",
    "- a pie chart count of extras type from extras_type column in ballbyball.csv in all_json folder in analysis folder followed by table for the same                                                                                                                                                  \n",
    "-table for total runs sum of runs_total column , total wicket sum of count of wicket_type column,total extras sum of runs_extras column , total balls bowled total number of rows in ballbyball.csv in all_json folder in analysis folder\n",
    "-bargraph for top 10 most run getter you can calc this from runs_batter column in batter.csv in player names in player folder in all_json folder in analysis folder\n",
    "-bargraph of top 10 wicket taker you can cal this from wicket_type column in bowler.csv in player names in player folder in all_json folder in analysis folder\n",
    "-bargrapg of top 10 most catch/runout taken then also make table for them for total number of catches total number of runouts you can cal this from fielder column in fielder.csv in player names in player folder in all_json folder in analysis folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
